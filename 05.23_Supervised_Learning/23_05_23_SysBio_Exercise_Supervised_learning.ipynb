{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Supervised Learning { display-mode: \"form\" }\n",
        "#@markdown This praktikum re-analyses gene expression measurements of two leukemia subtypes: acute lymphoblastic leukemia (ALL) and acute myeloid leukemia (AML) from ([Golub et al. 1999](https://doi.org/10.1126/science.286.5439.531)).\n",
        "#@markdown AML and ALL are treated with different drugs (May 9th quiz, last question).\n",
        "#@markdown Determining the leukemia subtype involves multiple tests, and an experienced hematopathologist to interpet them.\n",
        "#@markdown Here we aim to use supervised learning to train a classifier and predict the leukemia subtype from a single gene expression experiment.\n",
        "\n",
        "#@markdown The web site with the raw data referred to in ([Golub et al. 1999](https://doi.org/10.1126/science.286.5439.531)) is no longer accessible.\n",
        "#@markdown Luckily, the data can be found from other sources, we will use a version included in the [CAMAN package](https://cran.r-project.org/web/packages/CAMAN/index.html).\n",
        "#@markdown The current cell will set up the environment & load the gene expression measurements (`exprs`), and corresponding true labels as determined by clinical tests (`sample_labels`).\n",
        "\n",
        "#@markdown Some code cells will contain a red question mark (❓).\n",
        "#@markdown To make the most of the praktikum, try to fill in the missing code.\n",
        "#@markdown Typically, this will involve copying a few lines directly from above, and replacing variables or adjusting parameters.\n",
        "\n",
        "# Remove Colab `/content/sample_data/` directory to avoid confusion\n",
        "!rm -rf sample_data\n",
        "\n",
        "# Upgrade scikit-learn, as the default Colab version does not have `DecisionBoundaryDisplay`\n",
        "!pip install pyreadr\n",
        "\n",
        "# Download & unpack the CAMAN package\n",
        "!wget -nv https://cran.r-project.org/src/contrib/CAMAN_0.77.tar.gz\n",
        "!tar xvfz CAMAN_0.77.tar.gz > /dev/null\n",
        "\n",
        "# Import modules from numpy, pandas, seaborn, sklearn\n",
        "import requests\n",
        "import numpy as np, pandas as pd, seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.inspection, sklearn.metrics, sklearn.neighbors, sklearn.svm, sklearn.pipeline, sklearn.preprocessing\n",
        "import pyreadr\n",
        "\n",
        "# Fix `RANDOM_SEED` for (partial) reproducibility\n",
        "RANDOM_SEED = 4 # https://xkcd.com/221\n",
        "\n",
        "def plot_question_mark(ax):\n",
        "  ax.text(x=.5, y=.5, s='?', color='red', fontsize=64,\n",
        "          horizontalalignment='center',\n",
        "          verticalalignment='center',\n",
        "          transform=ax.transAxes)\n",
        "\n",
        "# Use g:Convert to map microarray probe identifiers to gene names\n",
        "def g_convert(query, target='ENSG', organism='hsapiens', simplify=False):\n",
        "  # https://biit.cs.ut.ee/gprofiler/convert\n",
        "  r = requests.post(url='https://biit.cs.ut.ee/gprofiler/api/convert/convert/', json=locals())\n",
        "  df = pd.DataFrame(r.json()['result'])\n",
        "  return df\n",
        "\n",
        "golubMerge = pyreadr.read_r('CAMAN/data/golubMerge.RData')\n",
        "exprs = golubMerge['golubMerge.exprs']\n",
        "sample_labels = golubMerge['sample.labels']\n",
        "print('Loading Golub et al. 1999 data:')\n",
        "print('- exprs:', exprs.shape)\n",
        "print('- sample_labels:', sample_labels.shape)"
      ],
      "metadata": {
        "id": "AT6rxVfO2RCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Data wrangling"
      ],
      "metadata": {
        "id": "u2FaLfM7yoCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expression measurements\n",
        "The gene expression matrix `exprs` has 7129 rows and 72 columns. The number of columns matches the number of samples in the training set (38) plus the number of samples in the validation set (34)."
      ],
      "metadata": {
        "id": "phH2CoXIZWrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exprs.head()"
      ],
      "metadata": {
        "id": "Dup6trgfiIWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The row names look like Affymetrix probe identifiers. We will use [g:Convert](https://biit.cs.ut.ee/gprofiler/convert) to transform them to gene names. We will also aggregate the probe-level measurements by taking the average of probes mapping to the same gene. "
      ],
      "metadata": {
        "id": "9Y5BtYv6WZJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gene_conversion = g_convert(exprs.index.tolist()).query('(n_converted == 1) & (name != \"None\")')\n",
        "gene_expression = exprs.merge(gene_conversion[['incoming', 'name']], left_index=True, right_on='incoming').drop(['incoming'], axis=1).set_index('name', drop=True).groupby('name').agg('mean')\n",
        "gene_expression"
      ],
      "metadata": {
        "id": "LdwVuiB0_R0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many gene-level measurements do we get? How does the number compare to what was reported in the original study (n=6817)? If the numbers are different, why?"
      ],
      "metadata": {
        "id": "P2OXWznvYtSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample labels\n",
        "According to the paper, the training set has 38 samples (27 ALL, 11 AML) and the validation set has 34 samples (20 ALL, 14 ALL; footnote 23). The total number of ALL and AML samples from the paper seems to match the contents of `sample_labels`."
      ],
      "metadata": {
        "id": "Cl4TsTMYLGtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_labels.value_counts()"
      ],
      "metadata": {
        "id": "SdRVnZVFgK5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, there's no explicit information on whether a sample belongs to the training set or the validation set. We first try using the first 38 samples as the training set (`samples_train`), and the remaining 34 samples as the validation set (`samples_valid`). This does not reproduce the number of ALL/AML samples in the training/validation sets as reported in the paper. Can you find an alternative partitioning that recapitulates ALL/AML counts? Look at the contents of `sample_labels` for additional clues.\n",
        "\n",
        "We then define training/validation subsets of gene expression and corresponding labels to use as input for supervised learning."
      ],
      "metadata": {
        "id": "NmSRfj1ogeVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#❓: Modify lines below to reproduce the train/validation sets from the original study\n",
        "# first 38 samples as the training set (`samples_train`), and the remaining 34 samples as the validation set (`samples_valid`)\n",
        "samples_train = range(0, 38)\n",
        "samples_valid = range(38, len(sample_labels))\n",
        "\n",
        "# Sample labels for training & validation sets (check counts)\n",
        "labels_train = sample_labels.loc[samples_train]\n",
        "labels_valid = sample_labels.loc[samples_valid]\n",
        "print('Labels, training:', labels_train.value_counts())\n",
        "print('Labels, validation:', labels_valid.value_counts())\n",
        "\n",
        "# Gene expression for training & validation sets\n",
        "expression_train = gene_expression.transpose().loc[samples_train]\n",
        "expression_valid = gene_expression.transpose().loc[samples_valid]\n",
        "print('Gene expression, training:', expression_train.shape)\n",
        "print('Gene expression, validation:', expression_valid.shape)\n",
        "\n",
        "# Gene expression + sample label together for traning & validation sets\n",
        "# (Useful for seabron visualisation routines.)\n",
        "data_train = pd.concat([expression_train, labels_train], axis=1)\n",
        "data_valid = pd.concat([expression_valid, labels_valid], axis=1)"
      ],
      "metadata": {
        "id": "hKznImitj67S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Single-feature classification\n",
        "\n",
        "The original study notes that ALL/AML subtypes were initially motivated by differences in periodic acid-Schiff (PAS) staining, and levels of myeloperoxidase. Could we differentiate between ALL/AML by using known biologically relevant genes?\n",
        "PAS staining in cancer cells detects excess glycogen, we somwehat arbitrarily pick HK2 as a PAS proxy. Similarly, we also look at expression levels for myeloperoxidase (MPO)."
      ],
      "metadata": {
        "id": "tQtQYCnZyN7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gene1, gene2 = 'HK2', 'MPO'\n",
        "\n",
        "# Plot with two sub-panels\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), constrained_layout=True)\n",
        "\n",
        "# Violin plot for GCK glucokinase\n",
        "ax1.set_title(gene1)\n",
        "sns.violinplot(data=data_train, x=gene1, y='sample.labels', ax=ax1);\n",
        "\n",
        "#❓: Add violin plot for MPO myeloperoxidase\n",
        "plot_question_mark(ax2)"
      ],
      "metadata": {
        "id": "HFE7vm7gdN_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gene expression looks different for both subgroups, let's look at the corresponding ROC curves and AUC scores."
      ],
      "metadata": {
        "id": "DwzyyyFnxo8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot with two sub-panels\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), constrained_layout=True)\n",
        "\n",
        "# Add ROC curve for GCK\n",
        "ax1.set_title(gene1)\n",
        "ax1.set_aspect('equal')\n",
        "sklearn.metrics.RocCurveDisplay.from_predictions(y_true=labels_train, y_pred=expression_train[gene1], pos_label='ALL', ax=ax1);\n",
        "\n",
        "#❓: Add ROC curve for MPO\n",
        "plot_question_mark(ax2)"
      ],
      "metadata": {
        "id": "DMDjSue6v9Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Visualising classifier output\n",
        "Both HK2 and MPO expression are different in ALL/AML, but neither alone would be sufficient for a clinically useful classification. We'll try to combine the two genes using a supervised learning method. Specifically, we will try a linear Support Vector Machine (SVM) and k-nearest neighbours classifier (KNN), as discussed in [this article](https://www.nature.com/articles/nmeth.4551) from the [Points of Significance series](https://www.nature.com/collections/qghhqm/pointsofsignificance).\n",
        "\n",
        "First, we train an SVM on HK2 and MPO expression, and visualise the corresponding decision surface and ROC curve for the training data."
      ],
      "metadata": {
        "id": "Gs6_IugkzRuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SVM on training data\n",
        "svm = sklearn.svm.SVC(kernel='linear', random_state=RANDOM_SEED)\n",
        "svm.fit(X=expression_train[[gene1, gene2]], y=np.ravel(labels_train))\n",
        "\n",
        "# Plot with two sub-panels\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), constrained_layout=True)\n",
        "\n",
        "# Left: decision boundary with training data\n",
        "sklearn.inspection.DecisionBoundaryDisplay.from_estimator(estimator=svm, X=expression_train[[gene1, gene2]], alpha=0.5, ax=ax1);\n",
        "sns.scatterplot(data=data_train, x=gene1, y=gene2, hue='sample.labels', ax=ax1);\n",
        "\n",
        "# Right: ROC curve (training data)\n",
        "sklearn.metrics.RocCurveDisplay.from_estimator(svm, X=expression_train[[gene1, gene2]], y=labels_train, pos_label='AML', ax=ax2);"
      ],
      "metadata": {
        "id": "q62InqnlgdL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also train a KNN classifier for comparison. We have changed n_neighbors from the default value (5) to 2, leading to a very high AUC score on the training data."
      ],
      "metadata": {
        "id": "jQM5R8QA886B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train knn on training data\n",
        "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=2)\n",
        "knn.fit(X=expression_train[[gene1, gene2]], y=np.ravel(labels_train))\n",
        "\n",
        "# Plot with two sub-panels\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), constrained_layout=True)\n",
        "\n",
        "#❓: Add decision boundary for knn \n",
        "plot_question_mark(ax1)\n",
        "\n",
        "#❓: Add ROC curve for knn\n",
        "plot_question_mark(ax2)"
      ],
      "metadata": {
        "id": "Ge4Nqz-tOPKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Training vs validation\n",
        "\n",
        "We'll now look at the performance of both models on the validation data. Which classifier would you expect to generalise better (e.g. looking at the decision boundaries above)?"
      ],
      "metadata": {
        "id": "LnMmd6Arz0vP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot with two sub-panels\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), constrained_layout=True)\n",
        "\n",
        "# Left: decision boundary with test data\n",
        "sklearn.inspection.DecisionBoundaryDisplay.from_estimator(estimator=svm, X=expression_valid[[gene1, gene2]], alpha=0.5, ax=ax1);\n",
        "sns.scatterplot(data=data_valid, x=gene1, y=gene2, hue='sample.labels', ax=ax1);\n",
        "\n",
        "# Right: ROC curve (test data)\n",
        "sklearn.metrics.RocCurveDisplay.from_estimator(svm, X=expression_valid[[gene1, gene2]], y=labels_valid, pos_label='AML', ax=ax2, name='linear SVM');"
      ],
      "metadata": {
        "id": "F9ucrrJqTUw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How would you expect KNN to perform when changing n_neighbors back to the default value (and re-training)?"
      ],
      "metadata": {
        "id": "TgUJXCOt9bHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot with two sub-panels\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(6, 3), constrained_layout=True)\n",
        "\n",
        "#❓: Add decision boundary for KNN on validation data\n",
        "plot_question_mark(ax1)\n",
        "\n",
        "#❓: Add ROC curve for KNN on validation data\n",
        "plot_question_mark(ax2)"
      ],
      "metadata": {
        "id": "BVZ5mftBUU_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 High-dimensional data\n",
        "\n",
        "We now switch to working with expression data from all genes. Running an SVM with default settings reproduces the 100% accuracy reported in the study. How does this change when using a different value for the regularization parameter C?"
      ],
      "metadata": {
        "id": "UKou5U9jmKxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot with two sub-panels\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8, 4), constrained_layout=True)\n",
        "ax1.set_aspect('equal')\n",
        "ax2.set_aspect('equal')\n",
        "\n",
        "svm_full = sklearn.svm.SVC(kernel='linear', random_state=RANDOM_SEED)\n",
        "svm_full.fit(X=expression_train, y=np.ravel(labels_train))\n",
        "\n",
        "sklearn.metrics.RocCurveDisplay.from_estimator(svm_full, expression_train, labels_train, ax=ax1, name='SVM training');\n",
        "sklearn.metrics.RocCurveDisplay.from_estimator(svm_full, expression_valid, labels_valid, ax=ax1, name='SVM validation');\n",
        "\n",
        "sklearn.metrics.ConfusionMatrixDisplay.from_estimator(estimator=svm_full, X=expression_valid, y=labels_valid, ax=ax2);"
      ],
      "metadata": {
        "id": "GDlbfbLX3iFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does a KNN classifier perform when trained on all genes? Feel free to try out different values for n_neighbors, like for the regularization parameter C for the SVM above. Can you rationalise the differences between an SVM and a KNN when working with a large number of features (mentioned in [this article](https://www.nature.com/articles/nmeth.4551))?"
      ],
      "metadata": {
        "id": "xh7788I_Yw9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot with two sub-panels\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8, 4), constrained_layout=True)\n",
        "ax1.set_aspect('equal')\n",
        "ax2.set_aspect('equal')\n",
        "\n",
        "#❓: Train a KNN on the full data set\n",
        "# knn_full = sklearn.neighbors.KNeighborsClassifier(...\n",
        "# knn_full.fit(...\n",
        "\n",
        "#❓: Plot ROC on train & validation data\n",
        "plot_question_mark(ax1)\n",
        "\n",
        "#❓: Plot confusion matrix on validation data\n",
        "plot_question_mark(ax2)"
      ],
      "metadata": {
        "id": "86vOGY184Bst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6 Model interpretability\n",
        "\n",
        "Many machine learning algorithms are able to estimate the contribution of each feature towards making correct classifications. In the original study, feature importance was quantified by correlating the expression of an individual gene to the sample labels. For a linear SVM, feature importance is often quantified with the coefficients of the separating hyperplane. The code below extracts the hyperplane weights (one per gene), normalises and ranks them."
      ],
      "metadata": {
        "id": "N-gWL8RbaNfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = expression_train.transpose()\n",
        "feature_importance.insert(loc=0, column='SVM_importance', value=svm_full.coef_[0] / max(abs(svm_full.coef_[0])))\n",
        "feature_importance.insert(loc=1, column='SVM_importance_pct', value=feature_importance['SVM_importance'].abs().rank(ascending=True, pct=True))\n",
        "feature_importance = feature_importance.sort_values('SVM_importance_pct', ascending=False)\n",
        "feature_importance.head(10)"
      ],
      "metadata": {
        "id": "-MQC2RnNpCzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two tables below show the top 5 ALL-enriched, and AML-enriched genes from Figure 3B of the original study (using updated gene names). Can you discuss the agreement between \n",
        "\n",
        "Conversely, can you find any additional evidence for the top SVM-supported genes in ALL or AML, either from the original study or from additional literature?"
      ],
      "metadata": {
        "id": "P_zxA1N9fOuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_genes = [\n",
        "  'MYB', # C-myb\n",
        "  'PSMA6', # Proteasome iota\n",
        "  'CD79A', # MB-1\n",
        "  'CCND3', # Cyclin D3\n",
        "  'MYL6B', # Myosin light chain\n",
        "]\n",
        "feature_importance.query('name in @all_genes')"
      ],
      "metadata": {
        "id": "EZhheXUfqbam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aml_genes = [\n",
        "  'FAH', # Fumarylacetoacetate\n",
        "  'ZYX', # Zyxin\n",
        "  'LTC4S', # LTC4 synthase\n",
        "  'LYN', # LYN\n",
        "  'HOXA9', #HoxA9\n",
        "]\n",
        "#❓: Show SVM weights for top AML genes"
      ],
      "metadata": {
        "id": "FR54jMA0bXaI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}